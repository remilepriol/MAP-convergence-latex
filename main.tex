\documentclass{article}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{microtype}      % microtypography
\usepackage{graphicx}
%\usepackage{subfigure}
\usepackage{subcaption}
\usepackage{hyperref}       % hyperlinks
\usepackage{tikz}           % define for loops

\hypersetup{ % SLJ: my standard paper setup...
	pdftitle={MAP convergence},
	pdfkeywords={},
	pdfborder=0 0 0,
	pdfpagemode=UseNone,
	colorlinks=true,
	linkcolor=blue, %mydarkblue,
	citecolor=blue, %mydarkblue,
	filecolor=blue, %mydarkblue,
	urlcolor=blue, %mydarkblue,
	pdfview=FitH,
	pdfauthor={Anonymous},
}

\usepackage[round]{natbib}
\renewcommand{\bibname}{References}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}

\newcommand{\RLP}[1]{\textcolor{red}{RLP:#1}}
\newcommand{\violet}[1]{\textcolor{violet}{#1}}

% my packages
\usepackage{math_commands}
% some custom math commands
\newtheorem{proposition}{Proposition}
\newcommand*{\expect}[2][]{\ensuremath{\mathbb{E}_{#1} \left[ #2 \right] }} % expectation operator
\newcommand{\logpartition}{A}
\newcommand{\conj}{\logpartition^*}
\newcommand{\bregman}{\cB_\logpartition}
\newcommand{\bregmanconj}{\cB_{\logpartition^*}}
\newcommand{\natp}{\theta}
\newcommand{\meanp}{\mu}
\newcommand{\decrement}{D}
\newcommand{\Dir}{\mathrm{Dir}} % Dirichlet
\newcommand{\linear}{\ell} % linearization of a function


\title{Convergence rate of MAP estimates \\
for the exponential family}
\author{R\'emi Le Priol}
\date{October 2020}


\begin{document}

\maketitle

\section{Background}
It's hard to find general convergence rate on the KL for the maximum likelihood estimates of the exponential family.  We want the simplest one.
We hope  to get a new result by combining tools from statistics and optimization. 


The exponential family member with sufficient statistic $T$ and natural parameter $\natp$ is the model
\begin{align}
    p(X|\natp) &= \exp( \natp^\top T(X) - \logpartition(\natp)) \; ,
\end{align}
with log-partition function 
\begin{align}
    \logpartition(\natp) = \log \int e^{\natp^\top T(x)} dx \; .
\end{align}
Recall that $\logpartition$ verifies the two following identities 
\begin{align}
    \nabla\logpartition(\natp) &=  \expect[p(X|\natp)]{T(X)} =: \meanp \\
    \nabla^2 \logpartition(\natp) &= \Cov_\natp[T(X)] > 0
\end{align}
where $\meanp$ is called the mean parameter.
The second identity entails that $\logpartition$ is strictly-convex.
The conjugate prior for this distribution is
\begin{align}
    \pi(\natp) &\propto \exp( - n_0 \bregman(\natp || \natp_0) )
\end{align}
where $n_0$ is a number of fictional points observed from a distribution with parameter $\natp_0$.
$\bregman(\natp || \natp_0)$ is the Bregman divergence induced by $\logpartition$ between $\natp$ and $\natp_0$
\begin{align}
    \bregman (\natp || \natp_0)
    & = \logpartition(\natp) - \logpartition(\natp_0) 
    - \langle \meanp_0 , \natp - \natp_0 \rangle
\end{align}
with $\meanp_0 = \nabla \logpartition(\natp_0) = \expect[\natp_0]{T(X)}$ the mean parameter associated to the natural parameter $\natp_0$.
The negative log-likelihood of the prior is then
\begin{align*}
    -\log \pi(\natp) = n_0 (\logpartition(\natp)  - \natp^\top \meanp_0 ) + \cst
\end{align*}
Thus the joint NLL of $(x_1,\dots,x_n,\natp)$ is
\begin{align}
    -\log p(X|\natp)\pi(\natp) 
    = (n_0+n) \logpartition (\natp) 
    - \theta^\top \left(n_0 \meanp_0 + \sum_{i=1}^n T(x_i) \right) \; .
\end{align}
Minimizing this expression over $\natp$ yields the Maximum A Posteriori estimate
\begin{align}
    \hat \natp = \argmin_\natp -\log p(X|\natp) + n_0 \bregman(\natp || \natp_0)
\end{align}
such that the MAP is
\begin{align}
    \nabla \logpartition(\hat \natp) = \hat \meanp
    = \frac{n_0 \meanp_0 + \sum_{i=1}^n T(X_i) }{n_0+n} \; .
\end{align}
The MAP estimate is a random quantity.

\section{Stochastic Proximal Bregman Point}
We see that the MAP estimate minimizes the sum of a stochastic loss $ -\log p(X|\natp)$ and a deterministic divergence to an initial point $n_0 \bregman(\natp || \natp_0)$. This is a stochastic proximal Bregman step with step-size $\inv{n_0}$. This can also be seen at each step since
\begin{align}
    \hat \natp_{n+1} 
    &= \argmin_\natp -\log p(x_{n+1}|\natp) + (n_0 + n) \bregman(\natp || \hat \natp_n) \\
    &= \argmin_\natp f(\natp) +  \inv{\gamma_n}\bregman(\natp || \hat \natp_n) \; .
\end{align}
Hence the MAP estimate can also be seen as the result of a stochastic proximal Bregman point algorithm with step-size $\gamma_n = \inv{n_0 + n}$ at step $n$.

This is similar to the online learning setup, and it may be possible to bound the regret, with approaches similar to Adagrad.

\section{Stochastic Mirror Descent}
It turns out that the MAP can also be seen as the trajectory of stochastic mirror descent
\begin{align}
    \hat \natp_{n+1} 
    &= \argmin_\natp 
    - \langle T(x_{t+1}), \natp \rangle  + \logpartition(\natp) + (n_0 + n) \bregman(\natp || \natp_n) \\
    %&(n_0+n)\left(\logpartition(\natp) - \logpartition(\natp_n) - \langle \nabla \logpartition(\natp_n)  , \natp - \natp_n \rangle \right)  \\
    &= \argmin_\natp - \langle T(x_{t+1}), \natp \rangle   + \logpartition(\natp_n) + \langle \nabla \logpartition(\natp_n)  , \natp - \natp_n \rangle + (n_0+n + 1) \bregman(\natp || \natp_n) \\
    &= \argmin_\natp \linear_f(\natp;\natp_n) + (n_0 + n + 1) \bregman(\natp || \natp_n)
\end{align}
where $\linear_f(\natp;\natp_n)$ is the linearization of $f$ at $\natp_n$ evaluated at $\natp$. 
This is the formula for stochastic mirror descent (SMD) applied to $f$ with mirror map $\logpartition$ and step-size $\gamma_n = \inv{n_0 + n + 1}$.

In the classic setting, SMD is studied under strong-convexity assumption on the mirror map $\logpartition$ \RLP{cite {bubeck}}.
In our setting this is not always true -- eg gaussians.
However a recent and fast-expanding body of work is concerned with a new assumption: relative smoothness and relative strong-convexity. 
For mirror descent, there are well linear and sublinear rate, even when the function is not smooth or strongly convex ! Beautiful. Cite nesterov, and teboulle, and the first birnbaum.

For stochastic mirror descent, there is  a sublinear rate (cite richtarik), but under a weird assumption on gradient's variance. Still need to check “Relative Continuity” for Non-Lipschitz Nonsmooth Convex Optimization Using Stochastic (or Deterministic) Mirror Descent".

Also cite "The Information Geometry of Mirror Descent", saying they only give asymptotic results.


\section{Straightforward Convergence Rate}
In the realizable case, the suboptimality on the population log-likelihood is exactly the KL between our current model and the true distribution
\begin{align}
    \expect[x\sim p(.|\natp^*)]{-\log p(x|\natp) + \log p(x|\natp^*)}
    &= \KL( p(.|\natp^*) || p(.|\natp)) \\
    &= \bregman (\natp || \natp^*) \\
    &= \bregmanconj ( \meanp^* || \meanp)
    %& = \logpartition(\natp) - \logpartition(\natp^*) - \meanp^{*\top}(\natp - \natp^*) \; .
\end{align}
where $\conj$ is the entropy, the convex conjugate of the log-partition.
The relationship between Bregman divergences and Fenchel conjugacy is well explained in Wainwright's book, and the article geometry of exponential family. 
The question is: how does this quantity behave when $\natp$ is the MAP estimate ? Can we get bounds -- in expectation or high-probability ? 

\paragraph{If $\conj$ is $L$-Lipschitz} (e.g. $\logpartition$ is defined within the $\ell^2$-ball of radius $L$), then
\begin{align}
    \bregmanconj(\mu^* || \mu) 
    \leq L \norm{\mu^* - \mu} + \norm{\natp} \norm{\mu^* - \mu}
    \leq 2L \norm{\mu^* - \mu}
\end{align}
so $\bregmanconj$ is $2L$-Lipschitz.
Since the empirical average converges in expectation to the population mean at a rate of $1/\sqrt{n}$ in $\ell^2$ norm, we know that this is the convergence rate of the log-likelihood. \RLP{find relevant inequalities}.

\paragraph{If $\conj$ is $L$-smooth} (e.g. $\logpartition$ is $L^{-1}$-strongly convex), then
\begin{align}
    \bregmanconj(\mu^* || \mu) 
    \leq \frac{L}{2} \norm{\mu^* - \mu}^2
\end{align}
so $\bregmanconj$ is upper bounded by a quadratic. In expectation, it should converge at a rate $1/n$.

\section{Self-Concordance}

A big problem is that $\conj$ is seldom Lipschitz or smooth. For instance the log-partition function of a multivariate normal is 
\begin{align}
    \logpartition(\eta, \Lambda) = \half \eta^\top \Lambda^{-1} \eta - \log\det(\Lambda)
\end{align}
which is defined on $\eta \in \real^d$ and $\Lambda\in \real^{d\times d}$ symmetric positive definite. 
It is not strongly convex, so $\conj$ is not smooth.

Another hypothesis that may be more suitable is self-concordance. $f: \real \rightarrow \real$ is SC if 
\begin{align}
    \abs{f'''(x)} \leq 2 f''(x)^{\frac{3}{2}} \; .
\end{align}
The exponent $\frac{3}{2}$ is motivated by dimensional analysis and the factor $2$ appears to simplify downstream calculus.
A multidimensional function $f: \real^n \rightarrow \real$ is SC if it's restriction to any line is SC.
Negative logarithm $-\log(x)$ and entropy $x\log(x)$ are both self-concordant function. This is good news for us since log-partition function may include SC logarithmic barriers.
In particular, gaussians have a logarithmic term. They also have an inverse term which is not self-concordant, but which is generalized self-concordant.

\subsection{Fenchel conjugate motivation to self-concordance}

In the most regular case, when $f(x)$ is a convex function, continuously differentiable on its domain, then its convex conjugate $f^*(y) = \max_x \langle x, y \rangle - f(x)$ verifies
\begin{align}
    \nabla f \circ \nabla f^*  &= \Id \\
     \nabla f^* \circ \nabla f &= \Id
\end{align}
where $\Id$ is the identity function on the relevant domain. In words, the gradients of $f$ and $f^*$ are reciprocal.
Deriving this equality yields
\begin{align}
    \nabla^2 f(x) \nabla^2 f^*(x^*) = I_n
\end{align}
where $x,x^*$ are conjugate points -- e.g. $x^*=\nabla f(x)$ and $x = \nabla f^*(x^*)$.
Now, it gets interesting to us when we derive again this equality. Let's tackle the 1D case first
\begin{align}
    &f''(x) f^{* \prime \prime}(f'(x)) = 1, \forall x \\
    \implies
    &f'''(x)f^{* \prime \prime}(f'(x))  + f''(x)^2 f^{* \prime \prime \prime}(f'(x))  = 0 \\
    \implies
    &\frac{f'''(x)}{f''(x){\frac{3}{2}}}  + \frac{f^{* \prime \prime \prime}(x^*)}{f^{* \prime \prime}(x^*){\frac{3}{2}}}  = 0
\end{align}
where to get to the last line we used the first line, and we divided the second line by $f''(x)^{\frac{1}{2}}$. 
We see that for a pair of conjugate functions, the self-concordance ratio is preserved, modulo the sign.
This gives another rational, beyond dimensional analysis, for using this ratio as a regularity assumption for convex analysis. 

It is also very helpful for us, since we are looking at pairs $\logpartition, \conj$, and their associated Bregman divergences. 
If $\logpartition$ is SC, then so is 
$f(\natp)= \bregman(\natp || \natp^*) = \logpartition(\natp) - \langle \meanp^*, \natp \rangle + \cst$. 
And $\conj$ is SC as well, thus  $h(\meanp) = \bregmanconj ( \meanp || \meanp^*)$ is SC.
But there is no reason for 
$g(\meanp) = \bregmanconj ( \meanp^* || \meanp) =  \cst - \conj(\meanp) - \langle \nabla \conj (\meanp), \meanp^* - \meanp \rangle $ to be SC. 

The multivariate generalization of this formula is a third order tensor equality
\begin{align}
    \nabla^2 f^{-\half} \nabla^3 f \nabla^2 f^{-1} + \nabla^2 f^{* -\half} \nabla^3 f^* \nabla^2 f^{* -1} = 0
\end{align}
where we omit  multiplication axis and functions take relevant argument $x$ or $x^*$. Consequently, a multivariate definition of self-concordance might take the form of an inequality on the 3d tensor $\nabla^2 f^{-\half} \nabla^3 f \nabla^2 f^{-1}$.

\subsection{Suboptimality and Newton Decrement}
An important property of self-concordant functions (cite Boyd's book, although Nesterov's may be better) is that their suboptimality  may be upper bounded by the Newton Decrement 
\begin{align}
    \decrement(x)^2 = \nabla f(x)^T \nabla^2 f(x)^{-1} \nabla f(x) \; .
\end{align}
In general, subtracting the minimum $f^*$ of $f$ , we have
\begin{align}
    f(x) - f* \leq - \decrement(x) - \log( 1- \decrement(x)) \; .
\end{align}
Note that this bound is vacuous for $\decrement(x)\geq 1$. For $y = \decrement(x) \leq 0.68$, we have $ - y - \log(1-y) \leq y^2$, so we get the bound
\begin{align}
    f(x) - f^* \leq \decrement(x)^2 = \nabla f(x)^T \nabla^2 f(x)^{-1} \nabla f(x) \; .
\end{align}

Our functions of interest is $f(\natp)= \bregman (\natp || \natp^*)= \bregmanconj ( \meanp^* || \meanp) = g(\meanp)$, with minimum $f^*=0$. 
If $\logpartition$ is self-concordant, then so is $f$, but not necessarily $g$.
The gradient and Hessian of $f$ are
\begin{align}
    f(\natp) 
    &= \logpartition(\natp) - \logpartition(\natp^*) - \langle \meanp^*, \natp - \natp^* \rangle \\
    \nabla f(\natp) 
    &= \meanp - \meanp^* = \expect[p(X|\natp)]{T(X)} - \expect[p(X|\natp^*)]{T(X)} \\
    \nabla^2 f(\natp) 
    &= \Sigma(\natp) = \Cov_{p(X|\natp)}[T(X)]
\end{align}
so that we get the bound.
\begin{align}
    \bregmanconj(\mu^* || \mu) 
    \leq \decrement(\natp)^2 
    = \norm{\mu^* - \mu(\theta)}^2_{\Sigma(\theta)^{-1}} 
    \leq 0.46
\end{align}
% If we were to use $g(\meanp)$ instead, we would get dirty third order derivatives
% \begin{align}
%     g(\meanp) 
%     &= \conj(\meanp^*) - \conj(\meanp) - \langle \natp, \meanp^* - \meanp \rangle \\
%     \nabla g(\meanp) 
%     &= -\natp - \nabla^2 \conj(\meanp) (\meanp^* - \meanp) + \natp \\
%     &= \nabla^2 \conj(\meanp) (\meanp - \meanp^*) \\
%     \nabla^2 g(\meanp) 
%     &= \nabla^2 \conj(\meanp) + \nabla^3 \conj(\meanp ) (\meanp - \meanp^*)
% \end{align}
% where the last expression involves a third order tensor.

Finally, if instead we were looking at a different function switching the role of $\meanp$ and $\meanp^*$,  $h(\meanp) = \bregmanconj ( \meanp || \meanp^*)$, then we would get
\begin{align}
    \nabla h(\meanp ) 
    &= \natp - \natp^* \\
    \nabla^2 h(\meanp ) 
    &= \nabla^2 \conj(\meanp) 
    = \nabla^2 \logpartition(\natp) ^{-1}
    = \Cov_{p(X|\natp)}[T(X)]^{-1}\\
    \implies 
    \decrement(\meanp)
    &= \Var_{p(X|\natp)}[(\natp - \natp^*)^T T(X)] \; .
\end{align}
This is just a remark. I don't think it can help us to get anywhere. 


\bibsection
\bibliography{}


\newpage

\section{MAP on Graphs}
Assume that the variable $X$ factors along some graph $G$. 
We write $G(i)$ the parents of $X_i$ in $G$. 
Then we model the conditional distribution of $X$ given parameter vector $\theta$ factors as
\begin{align}
    p(X|\natp) = \prod_i p(X_i | X_{G(i)};\natp_i)
\end{align}
where $\natp_i$ is the parameter associated to the mechanism $X_{G(i)} \rightarrow X_i$. 
Embracing the Bayesian viewpoint, the independent mechanism principle is embodied as independence between parameters
\begin{align}
    p(\natp) = \prod_i p(\natp_i) \; .
\end{align}
% In other words, we have the following assumptions on $(\natp,X)$
% \begin{align}
%     \indep_{i=1}^d \natp_i \\
%     \natp_i \indep X_{G(i)}
% \end{align}
Following these equations, the joint distribution on $(\natp,X)$ factors along a larger graph $G'$ which augments $G$ by adding nodes $\natp_i$ with arrows pointing to $X_i$, as illustrated in Figure~\ref{fig:joint_graph}.
\begin{figure}[h]
    \centering
    \begin{tikzpicture}[shorten >=1pt,->]
      \tikzstyle{vertex}=[draw, circle,minimum size=24pt,inner sep=0pt]
      \foreach \name/\txt/\x/\y in {x1/X_1/0/0, x2/X_2/3/0, x3/X_3/2/-1.5, t1/\theta_1/-1.5/-0.5, t2/\theta_2/4.5/-0.5, t3/\theta_3/0.5/-2}
        \node[vertex] (G-\name) at (\x,\y) {$\txt$};
    
      \foreach \from/\to in {x1/x2, x2/x3, x1/x3, t1/x1, t2/x2, t3/x3}
        \draw (G-\from) -- (G-\to);
    \end{tikzpicture}
    \caption{A graph $G'$ factorizing $(\natp,X)$. Although the graph restricted on $X$ does not encode any conditional independence, $G'$ does on the joint distribution.}
    \label{fig:joint_graph}
\end{figure}
With such a graph, the Bayesian posterior can be factorized as well
\begin{align}
    p(\natp|X) 
    &\propto  p(X|\natp) p(\natp)& \\
    & = \prod_i p(X_i | X_{G(i)};\natp_i) p(\natp_i)
    &(\indep_i \natp_i) \\
    & = \prod_i p(X_i | X_{G(i)};\natp_i) p(\natp_i\violet{|X_{G(i)}})
    &(\natp_i \indep X_{G(i)}) \\
    & = \prod_i p(X_i, \violet{\natp_i} | X_{G(i)})    &  \\
    & = \prod_i p(\natp_i| \violet{X_i}, X_{G(i)})p(X_i|X_{G(i)})    &  \\
    \implies p(\natp|X) 
    &= \prod_i p(\natp_i| \violet{X_i}, X_{G(i)}) \; .
\end{align}
In words, a consequence of the independence mechanism principle is that the posterior distribution of $\natp_i$ can be inferred solely from $X_i$ and its parents. 

\subsection{Equality of directions for 2 categorical variables}
In my paper on the analysis of causal speed, I proved the equivalence between sampling a joint distribution $\omega = p(A,B) \in \simplex_{K\times K}$ on $(A,B)\in \{1,\dots,K\}^2$ from a Dirichlet with parameter $\gamma\in \real_+^{K\times K}$ and sampling independently the marginal distribution $\mu = p(A)\in \simplex_K$ and the conditional distributions $\nu_i = p(B|A=i)\in\simplex_K$ from Dirichlets with respective parameters $\sum_{j=1}^K \gamma_{:,j} = \gamma \ones$ (matrix vector product) and $\gamma_{i,:}$
\begin{align}
    \underbrace{\Dir_{K^2}((\gamma_{i,j})_{i,j=1}^K) }_{p(\omega)}
    \equiv 
    \underbrace{\Dir_K\left( \gamma \ones \right)}_{p(\mu)} 
    \otimes \left (\bigotimes_{i=1}^K 
    \underbrace{\Dir_K((\gamma_{i,j})_j)}_{p(\nu_i)} 
    \right ) 
    \label{eq:dirichlet_factors}
\end{align}
Seeing data samples $(\cA,\cB) = (A_i,B_i)_{i=1}^n$ as one-hot encodings in $\real^K\times \real^K$, the posterior reads
\begin{align}
p(\mu|\cA) &= \Dir(\gamma\ones + \sum_i A_i)\\
p(\nu_k|\cA,\cB) &= \Dir(\gamma_{k,:} + \sum_i  A_{i,k} B_i ) \\
p(\omega | \cA,\cB) & = \Dir( \gamma + \sum_i A_i B_i^\top )  
\end{align}
where $A_i B_i^\top$ is the one hot matrix encoding of $A,B$.
These three posteriors are obtained independently of each other following rules of calculus for Dirichlet distributions. Yet they happen to define the same distribution on distributions, as we verify below with the two equalities from equation \eqref{eq:dirichlet_factors}.
\begin{align}
    \left(\gamma + \sum_i A_i B_i^\top \right)_{k,l} 
    &= \left(\gamma_{k,:} + \sum_i  A_{i,k} B_i \right)_l \\
    \left(\gamma + \sum_i A_i B_i^\top \right) \ones 
    &= \gamma \ones + \sum_i A_i \; .
\end{align}
The interpretation of this result is that \emph{taking the posterior with the decomposition $A\rightarrow B$ or $B\rightarrow A$ give the same result}. As a corollary the MAP is also the same
\begin{align}
\hat \omega^\text{MAP} 
= \frac{\gamma + \sum_i A_i B_i^\top}{\ones^\top (\gamma + \sum_i A_i B_i^\top) \ones}
=\frac{\gamma + \sum_i A_i B_i^\top}{n_0 + n}
\end{align}
Using Bayesian statistics with this prior, there is no distinction between directions.

Is this bound to happen with a symmetric prior ? Let's give a name to the change of variable $f(\omega) = \mu,\nu$. 
Remark that $f(\omega^\top) = \mu_\leftarrow, \nu_\leftarrow$, eg in the categorical special case transposing omega and changing variables give the anticausal direction. 
For sure  $p(X|\mu,\nu) = p(X|f(\omega)) = p(X|\omega)$. 
Using the change of variable formula  we get something.
But which equality am I looking for exactly ? 
\end{document}
